<!DOCTYPE html>


<!--
 | Generated by Apache Maven Doxia Site Renderer 1.11.1 from target/generated-site/markdown/models.md at 2022-12-27
 | Rendered using Apache Maven Fluido Skin 1.11.1
-->
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="generator" content="Apache Maven Doxia Site Renderer 1.11.1" />
    <title>babzel &#x2013; Pre-trained models</title>
    <link rel="stylesheet" href="./css/apache-maven-fluido-1.11.1.min.css" />
    <link rel="stylesheet" href="./css/site.css" />
    <link rel="stylesheet" href="./css/print.css" media="print" />
    <script src="./js/apache-maven-fluido-1.11.1.min.js"></script>
  </head>
  <body class="topBarDisabled">
    <div class="container-fluid">
      <header>
        <div id="banner">
          <div class="pull-left"><div id="bannerLeft"><h1>babzel - OpenNLP models generator</h1>
</div>
</div>
          <div class="pull-right"></div>
          <div class="clear"><hr/></div>
        </div>

        <div id="breadcrumbs">
          <ul class="breadcrumb">
        <li id="publishDate">Last Published: 2022-12-27<span class="divider">|</span>
</li>
          <li id="projectVersion">Version: LATEST-SNAPSHOT</li>
          </ul>
        </div>
      </header>
      <div class="row-fluid">
        <header id="leftColumn" class="span2">
          <nav class="well sidebar-nav">
  <ul class="nav nav-list">
   <li class="nav-header">Pages</li>
    <li><a href="index.html" title="Project description"><span class="none"></span>Project description</a></li>
    <li class="active"><a><span class="none"></span>Pre-trained models</a></li>
  </ul>
          </nav>
          <div class="well sidebar-nav">
            <div id="poweredBy">
              <div class="clear"></div>
              <div class="clear"></div>
              <div class="clear"></div>
<a href="http://maven.apache.org/" title="Built by Maven" class="poweredBy"><img class="builtBy" alt="Built by Maven" src="./images/logos/maven-feather.png" /></a>
            </div>
          </div>
        </header>
        <main id="bodyColumn"  class="span10" >
<h1>Pre-trained models</h1>
<ol style="list-style-type: decimal">

<li>language code: <b>cs</b>, language name: <b>czech</b>, training sample size: <b>114k</b>
<ul>

<li>cs-simple
<ul>

<li>model file: <b><a href="models/cs-simple/cs-sentence-detector.onlpm">cs-sentence-detector.onlpm</a></b>, evaluation report: <b><a href="models/cs-simple/cs-sentence-detector.txt">cs-sentence-detector.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>0.854416260431298</b></li>
<li>model file: <b><a href="models/cs-simple/cs-tokenizer.onlpm">cs-tokenizer.onlpm</a></b>, evaluation report: <b><a href="models/cs-simple/cs-tokenizer.txt">cs-tokenizer.txt</a></b>, training algorithm: <b>MAXENT_QN</b>, evaluation score: <b>0.9991983144278562</b></li>
<li>model file: <b><a href="models/cs-simple/cs-pos-tagger.onlpm">cs-pos-tagger.onlpm</a></b>, evaluation report: <b><a href="models/cs-simple/cs-pos-tagger.txt">cs-pos-tagger.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>0.9820260035857671</b></li>
<li>model file: <b><a href="models/cs-simple/cs-lemmatizer.onlpm">cs-lemmatizer.onlpm</a></b>, evaluation report: <b><a href="models/cs-simple/cs-lemmatizer.txt">cs-lemmatizer.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>0.9813485916606076</b></li>
</ul>
</li>
<li>cs-lucene
<ul>

<li>model file: <b><a href="models/cs-lucene/cs-sentence-detector.onlpm">cs-sentence-detector.onlpm</a></b>, evaluation report: <b><a href="models/cs-lucene/cs-sentence-detector.txt">cs-sentence-detector.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>0.8542389687654933</b></li>
<li>model file: <b><a href="models/cs-lucene/cs-tokenizer.onlpm">cs-tokenizer.onlpm</a></b>, evaluation report: <b><a href="models/cs-lucene/cs-tokenizer.txt">cs-tokenizer.txt</a></b>, training algorithm: <b>MAXENT_QN</b>, evaluation score: <b>0.9991666911314708</b></li>
<li>model file: <b><a href="models/cs-lucene/cs-pos-tagger.onlpm">cs-pos-tagger.onlpm</a></b>, evaluation report: <b><a href="models/cs-lucene/cs-pos-tagger.txt">cs-pos-tagger.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>0.9736125474752858</b></li>
<li>model file: <b><a href="models/cs-lucene/cs-lemmatizer.onlpm">cs-lemmatizer.onlpm</a></b>, evaluation report: <b><a href="models/cs-lucene/cs-lemmatizer.txt">cs-lemmatizer.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>0.9811589163215629</b></li>
</ul>
</li>
</ul>
</li>
<li>language code: <b>da</b>, language name: <b>danish</b>, training sample size: <b>4k</b>
<ul>

<li>da-simple
<ul>

<li>model file: <b><a href="models/da-simple/da-sentence-detector.onlpm">da-sentence-detector.onlpm</a></b>, evaluation report: <b><a href="models/da-simple/da-sentence-detector.txt">da-sentence-detector.txt</a></b>, training algorithm: <b>MAXENT_QN</b>, evaluation score: <b>0.8776844070961718</b></li>
<li>model file: <b><a href="models/da-simple/da-tokenizer.onlpm">da-tokenizer.onlpm</a></b>, evaluation report: <b><a href="models/da-simple/da-tokenizer.txt">da-tokenizer.txt</a></b>, training algorithm: <b>MAXENT_QN</b>, evaluation score: <b>0.9975722142397067</b></li>
<li>model file: <b><a href="models/da-simple/da-pos-tagger.onlpm">da-pos-tagger.onlpm</a></b>, evaluation report: <b><a href="models/da-simple/da-pos-tagger.txt">da-pos-tagger.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>0.925279952432861</b></li>
<li>model file: <b><a href="models/da-simple/da-lemmatizer.onlpm">da-lemmatizer.onlpm</a></b>, evaluation report: <b><a href="models/da-simple/da-lemmatizer.txt">da-lemmatizer.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>0.9652165295808146</b></li>
</ul>
</li>
<li>da-lucene
<ul>

<li>model file: <b><a href="models/da-lucene/da-sentence-detector.onlpm">da-sentence-detector.onlpm</a></b>, evaluation report: <b><a href="models/da-lucene/da-sentence-detector.txt">da-sentence-detector.txt</a></b>, training algorithm: <b>MAXENT_QN</b>, evaluation score: <b>0.8718428437792329</b></li>
<li>model file: <b><a href="models/da-lucene/da-tokenizer.onlpm">da-tokenizer.onlpm</a></b>, evaluation report: <b><a href="models/da-lucene/da-tokenizer.txt">da-tokenizer.txt</a></b>, training algorithm: <b>MAXENT_QN</b>, evaluation score: <b>0.9972741240025773</b></li>
<li>model file: <b><a href="models/da-lucene/da-pos-tagger.onlpm">da-pos-tagger.onlpm</a></b>, evaluation report: <b><a href="models/da-lucene/da-pos-tagger.txt">da-pos-tagger.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>0.9239916757506689</b></li>
<li>model file: <b><a href="models/da-lucene/da-lemmatizer.onlpm">da-lemmatizer.onlpm</a></b>, evaluation report: <b><a href="models/da-lucene/da-lemmatizer.txt">da-lemmatizer.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>0.9646219403428798</b></li>
</ul>
</li>
</ul>
</li>
<li>language code: <b>de</b>, language name: <b>german</b>, training sample size: <b>65k</b>
<ul>

<li>de-simple
<ul>

<li>model file: <b><a href="models/de-simple/de-sentence-detector.onlpm">de-sentence-detector.onlpm</a></b>, evaluation report: <b><a href="models/de-simple/de-sentence-detector.txt">de-sentence-detector.txt</a></b>, training algorithm: <b>MAXENT_QN</b>, evaluation score: <b>0.7249962286921103</b></li>
<li>model file: <b><a href="models/de-simple/de-tokenizer.onlpm">de-tokenizer.onlpm</a></b>, evaluation report: <b><a href="models/de-simple/de-tokenizer.txt">de-tokenizer.txt</a></b>, training algorithm: <b>MAXENT_QN</b>, evaluation score: <b>0.997836506303655</b></li>
<li>model file: <b><a href="models/de-simple/de-pos-tagger.onlpm">de-pos-tagger.onlpm</a></b>, evaluation report: <b><a href="models/de-simple/de-pos-tagger.txt">de-pos-tagger.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>0.9466097318035932</b></li>
<li>model file: <b><a href="models/de-simple/de-lemmatizer.onlpm">de-lemmatizer.onlpm</a></b>, evaluation report: <b><a href="models/de-simple/de-lemmatizer.txt">de-lemmatizer.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>0.9665492308259859</b></li>
</ul>
</li>
<li>de-lucene
<ul>

<li>model file: <b><a href="models/de-lucene/de-sentence-detector.onlpm">de-sentence-detector.onlpm</a></b>, evaluation report: <b><a href="models/de-lucene/de-sentence-detector.txt">de-sentence-detector.txt</a></b>, training algorithm: <b>MAXENT_QN</b>, evaluation score: <b>0.7208512565089427</b></li>
<li>model file: <b><a href="models/de-lucene/de-tokenizer.onlpm">de-tokenizer.onlpm</a></b>, evaluation report: <b><a href="models/de-lucene/de-tokenizer.txt">de-tokenizer.txt</a></b>, training algorithm: <b>MAXENT_QN</b>, evaluation score: <b>0.9979193555054405</b></li>
<li>model file: <b><a href="models/de-lucene/de-pos-tagger.onlpm">de-pos-tagger.onlpm</a></b>, evaluation report: <b><a href="models/de-lucene/de-pos-tagger.txt">de-pos-tagger.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>0.9462410095101448</b></li>
<li>model file: <b><a href="models/de-lucene/de-lemmatizer.onlpm">de-lemmatizer.onlpm</a></b>, evaluation report: <b><a href="models/de-lucene/de-lemmatizer.txt">de-lemmatizer.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>0.9660062910435406</b></li>
</ul>
</li>
</ul>
</li>
<li>language code: <b>el</b>, language name: <b>greek</b>, training sample size: <b>2k</b>
<ul>

<li>el-simple
<ul>

<li>model file: <b><a href="models/el-simple/el-sentence-detector.onlpm">el-sentence-detector.onlpm</a></b>, evaluation report: <b><a href="models/el-simple/el-sentence-detector.txt">el-sentence-detector.txt</a></b>, training algorithm: <b>MAXENT_QN</b>, evaluation score: <b>0.9158110882956879</b></li>
<li>model file: <b><a href="models/el-simple/el-tokenizer.onlpm">el-tokenizer.onlpm</a></b>, evaluation report: <b><a href="models/el-simple/el-tokenizer.txt">el-tokenizer.txt</a></b>, training algorithm: <b>MAXENT_QN</b>, evaluation score: <b>0.9997652765824271</b></li>
<li>model file: <b><a href="models/el-simple/el-pos-tagger.onlpm">el-pos-tagger.onlpm</a></b>, evaluation report: <b><a href="models/el-simple/el-pos-tagger.txt">el-pos-tagger.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>0.9527386541471049</b></li>
<li>model file: <b><a href="models/el-simple/el-lemmatizer.onlpm">el-lemmatizer.onlpm</a></b>, evaluation report: <b><a href="models/el-simple/el-lemmatizer.txt">el-lemmatizer.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>0.9549295774647887</b></li>
</ul>
</li>
<li>el-lucene
<ul>

<li>model file: <b><a href="models/el-lucene/el-sentence-detector.onlpm">el-sentence-detector.onlpm</a></b>, evaluation report: <b><a href="models/el-lucene/el-sentence-detector.txt">el-sentence-detector.txt</a></b>, training algorithm: <b>MAXENT_QN</b>, evaluation score: <b>0.9026915113871635</b></li>
<li>model file: <b><a href="models/el-lucene/el-tokenizer.onlpm">el-tokenizer.onlpm</a></b>, evaluation report: <b><a href="models/el-lucene/el-tokenizer.txt">el-tokenizer.txt</a></b>, training algorithm: <b>MAXENT_QN</b>, evaluation score: <b>0.9992842942345924</b></li>
<li>model file: <b><a href="models/el-lucene/el-pos-tagger.onlpm">el-pos-tagger.onlpm</a></b>, evaluation report: <b><a href="models/el-lucene/el-pos-tagger.txt">el-pos-tagger.txt</a></b>, training algorithm: <b>PERCEPTRON</b>, evaluation score: <b>0.953706649697741</b></li>
<li>model file: <b><a href="models/el-lucene/el-lemmatizer.onlpm">el-lemmatizer.onlpm</a></b>, evaluation report: <b><a href="models/el-lucene/el-lemmatizer.txt">el-lemmatizer.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>0.9567292395800191</b></li>
</ul>
</li>
</ul>
</li>
<li>language code: <b>en</b>, language name: <b>english</b>, training sample size: <b>35k</b>
<ul>

<li>en-simple
<ul>

<li>model file: <b><a href="models/en-simple/en-sentence-detector.onlpm">en-sentence-detector.onlpm</a></b>, evaluation report: <b><a href="models/en-simple/en-sentence-detector.txt">en-sentence-detector.txt</a></b>, training algorithm: <b>MAXENT_QN</b>, evaluation score: <b>0.7524475524475526</b></li>
<li>model file: <b><a href="models/en-simple/en-tokenizer.onlpm">en-tokenizer.onlpm</a></b>, evaluation report: <b><a href="models/en-simple/en-tokenizer.txt">en-tokenizer.txt</a></b>, training algorithm: <b>MAXENT_QN</b>, evaluation score: <b>0.9913035447675045</b></li>
<li>model file: <b><a href="models/en-simple/en-pos-tagger.onlpm">en-pos-tagger.onlpm</a></b>, evaluation report: <b><a href="models/en-simple/en-pos-tagger.txt">en-pos-tagger.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>0.9409465979288474</b></li>
<li>model file: <b><a href="models/en-simple/en-lemmatizer.onlpm">en-lemmatizer.onlpm</a></b>, evaluation report: <b><a href="models/en-simple/en-lemmatizer.txt">en-lemmatizer.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>0.9834668510363278</b></li>
</ul>
</li>
<li>en-lucene
<ul>

<li>model file: <b><a href="models/en-lucene/en-sentence-detector.onlpm">en-sentence-detector.onlpm</a></b>, evaluation report: <b><a href="models/en-lucene/en-sentence-detector.txt">en-sentence-detector.txt</a></b>, training algorithm: <b>MAXENT_QN</b>, evaluation score: <b>0.7524142757172849</b></li>
<li>model file: <b><a href="models/en-lucene/en-tokenizer.onlpm">en-tokenizer.onlpm</a></b>, evaluation report: <b><a href="models/en-lucene/en-tokenizer.txt">en-tokenizer.txt</a></b>, training algorithm: <b>MAXENT_QN</b>, evaluation score: <b>0.9917777453023928</b></li>
<li>model file: <b><a href="models/en-lucene/en-pos-tagger.onlpm">en-pos-tagger.onlpm</a></b>, evaluation report: <b><a href="models/en-lucene/en-pos-tagger.txt">en-pos-tagger.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>0.9405953971566258</b></li>
<li>model file: <b><a href="models/en-lucene/en-lemmatizer.onlpm">en-lemmatizer.onlpm</a></b>, evaluation report: <b><a href="models/en-lucene/en-lemmatizer.txt">en-lemmatizer.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>0.9828857095674889</b></li>
</ul>
</li>
</ul>
</li>
<li>language code: <b>es</b>, language name: <b>spanish</b>, training sample size: <b>30k</b>
<ul>

<li>es-simple
<ul>

<li>model file: <b><a href="models/es-simple/es-sentence-detector.onlpm">es-sentence-detector.onlpm</a></b>, evaluation report: <b><a href="models/es-simple/es-sentence-detector.txt">es-sentence-detector.txt</a></b>, training algorithm: <b>MAXENT_QN</b>, evaluation score: <b>0.9657375145180024</b></li>
<li>model file: <b><a href="models/es-simple/es-tokenizer.onlpm">es-tokenizer.onlpm</a></b>, evaluation report: <b><a href="models/es-simple/es-tokenizer.txt">es-tokenizer.txt</a></b>, training algorithm: <b>MAXENT_QN</b>, evaluation score: <b>0.9990682588527999</b></li>
<li>model file: <b><a href="models/es-simple/es-pos-tagger.onlpm">es-pos-tagger.onlpm</a></b>, evaluation report: <b><a href="models/es-simple/es-pos-tagger.txt">es-pos-tagger.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>0.9430662366658398</b></li>
<li>model file: <b><a href="models/es-simple/es-lemmatizer.onlpm">es-lemmatizer.onlpm</a></b>, evaluation report: <b><a href="models/es-simple/es-lemmatizer.txt">es-lemmatizer.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>0.9889398825766973</b></li>
</ul>
</li>
<li>es-lucene
<ul>

<li>model file: <b><a href="models/es-lucene/es-sentence-detector.onlpm">es-sentence-detector.onlpm</a></b>, evaluation report: <b><a href="models/es-lucene/es-sentence-detector.txt">es-sentence-detector.txt</a></b>, training algorithm: <b>MAXENT_QN</b>, evaluation score: <b>0.967498549042368</b></li>
<li>model file: <b><a href="models/es-lucene/es-tokenizer.onlpm">es-tokenizer.onlpm</a></b>, evaluation report: <b><a href="models/es-lucene/es-tokenizer.txt">es-tokenizer.txt</a></b>, training algorithm: <b>MAXENT_QN</b>, evaluation score: <b>0.9991845281841154</b></li>
<li>model file: <b><a href="models/es-lucene/es-pos-tagger.onlpm">es-pos-tagger.onlpm</a></b>, evaluation report: <b><a href="models/es-lucene/es-pos-tagger.txt">es-pos-tagger.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>0.9406754592653794</b></li>
<li>model file: <b><a href="models/es-lucene/es-lemmatizer.onlpm">es-lemmatizer.onlpm</a></b>, evaluation report: <b><a href="models/es-lucene/es-lemmatizer.txt">es-lemmatizer.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>0.9891571549517019</b></li>
</ul>
</li>
</ul>
</li>
<li>language code: <b>fi</b>, language name: <b>finnish</b>, training sample size: <b>32k</b>
<ul>

<li>fi-simple
<ul>

<li>model file: <b><a href="models/fi-simple/fi-sentence-detector.onlpm">fi-sentence-detector.onlpm</a></b>, evaluation report: <b><a href="models/fi-simple/fi-sentence-detector.txt">fi-sentence-detector.txt</a></b>, training algorithm: <b>NAIVEBAYES</b>, evaluation score: <b>0.809776207302709</b></li>
<li>model file: <b><a href="models/fi-simple/fi-tokenizer.onlpm">fi-tokenizer.onlpm</a></b>, evaluation report: <b><a href="models/fi-simple/fi-tokenizer.txt">fi-tokenizer.txt</a></b>, training algorithm: <b>MAXENT_QN</b>, evaluation score: <b>0.9959646107822545</b></li>
<li>model file: <b><a href="models/fi-simple/fi-pos-tagger.onlpm">fi-pos-tagger.onlpm</a></b>, evaluation report: <b><a href="models/fi-simple/fi-pos-tagger.txt">fi-pos-tagger.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>0.8883146415835443</b></li>
<li>model file: <b><a href="models/fi-simple/fi-lemmatizer.onlpm">fi-lemmatizer.onlpm</a></b>, evaluation report: <b><a href="models/fi-simple/fi-lemmatizer.txt">fi-lemmatizer.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>0.9182128275363067</b></li>
</ul>
</li>
<li>fi-lucene
<ul>

<li>model file: <b><a href="models/fi-lucene/fi-sentence-detector.onlpm">fi-sentence-detector.onlpm</a></b>, evaluation report: <b><a href="models/fi-lucene/fi-sentence-detector.txt">fi-sentence-detector.txt</a></b>, training algorithm: <b>MAXENT_QN</b>, evaluation score: <b>0.8164102564102564</b></li>
<li>model file: <b><a href="models/fi-lucene/fi-tokenizer.onlpm">fi-tokenizer.onlpm</a></b>, evaluation report: <b><a href="models/fi-lucene/fi-tokenizer.txt">fi-tokenizer.txt</a></b>, training algorithm: <b>MAXENT_QN</b>, evaluation score: <b>0.9965085388994307</b></li>
<li>model file: <b><a href="models/fi-lucene/fi-pos-tagger.onlpm">fi-pos-tagger.onlpm</a></b>, evaluation report: <b><a href="models/fi-lucene/fi-pos-tagger.txt">fi-pos-tagger.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>0.888995067021359</b></li>
<li>model file: <b><a href="models/fi-lucene/fi-lemmatizer.onlpm">fi-lemmatizer.onlpm</a></b>, evaluation report: <b><a href="models/fi-lucene/fi-lemmatizer.txt">fi-lemmatizer.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>0.9270384049174824</b></li>
</ul>
</li>
</ul>
</li>
<li>language code: <b>fr</b>, language name: <b>french</b>, training sample size: <b>26k</b>
<ul>

<li>fr-simple
<ul>

<li>model file: <b><a href="models/fr-simple/fr-sentence-detector.onlpm">fr-sentence-detector.onlpm</a></b>, evaluation report: <b><a href="models/fr-simple/fr-sentence-detector.txt">fr-sentence-detector.txt</a></b>, training algorithm: <b>MAXENT_QN</b>, evaluation score: <b>0.9046702816162322</b></li>
<li>model file: <b><a href="models/fr-simple/fr-tokenizer.onlpm">fr-tokenizer.onlpm</a></b>, evaluation report: <b><a href="models/fr-simple/fr-tokenizer.txt">fr-tokenizer.txt</a></b>, training algorithm: <b>MAXENT_QN</b>, evaluation score: <b>0.9983173057382314</b></li>
<li>model file: <b><a href="models/fr-simple/fr-pos-tagger.onlpm">fr-pos-tagger.onlpm</a></b>, evaluation report: <b><a href="models/fr-simple/fr-pos-tagger.txt">fr-pos-tagger.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>0.9610752545079513</b></li>
<li>model file: <b><a href="models/fr-simple/fr-lemmatizer.onlpm">fr-lemmatizer.onlpm</a></b>, evaluation report: <b><a href="models/fr-simple/fr-lemmatizer.txt">fr-lemmatizer.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>0.9882061348060417</b></li>
</ul>
</li>
<li>fr-lucene
<ul>

<li>model file: <b><a href="models/fr-lucene/fr-sentence-detector.onlpm">fr-sentence-detector.onlpm</a></b>, evaluation report: <b><a href="models/fr-lucene/fr-sentence-detector.txt">fr-sentence-detector.txt</a></b>, training algorithm: <b>MAXENT_QN</b>, evaluation score: <b>0.9197842352531757</b></li>
<li>model file: <b><a href="models/fr-lucene/fr-tokenizer.onlpm">fr-tokenizer.onlpm</a></b>, evaluation report: <b><a href="models/fr-lucene/fr-tokenizer.txt">fr-tokenizer.txt</a></b>, training algorithm: <b>MAXENT_QN</b>, evaluation score: <b>0.9981232431014843</b></li>
<li>model file: <b><a href="models/fr-lucene/fr-pos-tagger.onlpm">fr-pos-tagger.onlpm</a></b>, evaluation report: <b><a href="models/fr-lucene/fr-pos-tagger.txt">fr-pos-tagger.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>0.9561566073962768</b></li>
<li>model file: <b><a href="models/fr-lucene/fr-lemmatizer.onlpm">fr-lemmatizer.onlpm</a></b>, evaluation report: <b><a href="models/fr-lucene/fr-lemmatizer.txt">fr-lemmatizer.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>0.9878787878787879</b></li>
</ul>
</li>
</ul>
</li>
<li>language code: <b>he</b>, language name: <b>hebrew</b>, training sample size: <b>8k</b>
<ul>

<li>he-simple
<ul>

<li>model file: <b><a href="models/he-simple/he-sentence-detector.onlpm">he-sentence-detector.onlpm</a></b>, evaluation report: <b><a href="models/he-simple/he-sentence-detector.txt">he-sentence-detector.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>0.9492293744333635</b></li>
<li>model file: <b><a href="models/he-simple/he-tokenizer.onlpm">he-tokenizer.onlpm</a></b>, evaluation report: <b><a href="models/he-simple/he-tokenizer.txt">he-tokenizer.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>0.9079439415650229</b></li>
<li>model file: <b><a href="models/he-simple/he-pos-tagger.onlpm">he-pos-tagger.onlpm</a></b>, evaluation report: <b><a href="models/he-simple/he-pos-tagger.txt">he-pos-tagger.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>0.9410195254072846</b></li>
<li>model file: <b><a href="models/he-simple/he-lemmatizer.onlpm">he-lemmatizer.onlpm</a></b>, evaluation report: <b><a href="models/he-simple/he-lemmatizer.txt">he-lemmatizer.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>0.9612321623478999</b></li>
</ul>
</li>
<li>he-lucene
<ul>

<li>model file: <b><a href="models/he-lucene/he-sentence-detector.onlpm">he-sentence-detector.onlpm</a></b>, evaluation report: <b><a href="models/he-lucene/he-sentence-detector.txt">he-sentence-detector.txt</a></b>, training algorithm: <b>PERCEPTRON</b>, evaluation score: <b>0.9458352298588985</b></li>
<li>model file: <b><a href="models/he-lucene/he-tokenizer.onlpm">he-tokenizer.onlpm</a></b>, evaluation report: <b><a href="models/he-lucene/he-tokenizer.txt">he-tokenizer.txt</a></b>, training algorithm: <b>MAXENT_QN</b>, evaluation score: <b>0.9192572869460951</b></li>
<li>model file: <b><a href="models/he-lucene/he-pos-tagger.onlpm">he-pos-tagger.onlpm</a></b>, evaluation report: <b><a href="models/he-lucene/he-pos-tagger.txt">he-pos-tagger.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>0.9413731343283582</b></li>
<li>model file: <b><a href="models/he-lucene/he-lemmatizer.onlpm">he-lemmatizer.onlpm</a></b>, evaluation report: <b><a href="models/he-lucene/he-lemmatizer.txt">he-lemmatizer.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>0.9603582089552238</b></li>
</ul>
</li>
</ul>
</li>
<li>language code: <b>it</b>, language name: <b>italian</b>, training sample size: <b>34k</b>
<ul>

<li>it-simple
<ul>

<li>model file: <b><a href="models/it-simple/it-sentence-detector.onlpm">it-sentence-detector.onlpm</a></b>, evaluation report: <b><a href="models/it-simple/it-sentence-detector.txt">it-sentence-detector.txt</a></b>, training algorithm: <b>MAXENT_QN</b>, evaluation score: <b>0.6965811965811965</b></li>
<li>model file: <b><a href="models/it-simple/it-tokenizer.onlpm">it-tokenizer.onlpm</a></b>, evaluation report: <b><a href="models/it-simple/it-tokenizer.txt">it-tokenizer.txt</a></b>, training algorithm: <b>MAXENT_QN</b>, evaluation score: <b>0.996915638546182</b></li>
<li>model file: <b><a href="models/it-simple/it-pos-tagger.onlpm">it-pos-tagger.onlpm</a></b>, evaluation report: <b><a href="models/it-simple/it-pos-tagger.txt">it-pos-tagger.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>0.9550744542431691</b></li>
<li>model file: <b><a href="models/it-simple/it-lemmatizer.onlpm">it-lemmatizer.onlpm</a></b>, evaluation report: <b><a href="models/it-simple/it-lemmatizer.txt">it-lemmatizer.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>0.9840971519444845</b></li>
</ul>
</li>
<li>it-lucene
<ul>

<li>model file: <b><a href="models/it-lucene/it-sentence-detector.onlpm">it-sentence-detector.onlpm</a></b>, evaluation report: <b><a href="models/it-lucene/it-sentence-detector.txt">it-sentence-detector.txt</a></b>, training algorithm: <b>MAXENT_QN</b>, evaluation score: <b>0.6993963782696178</b></li>
<li>model file: <b><a href="models/it-lucene/it-tokenizer.onlpm">it-tokenizer.onlpm</a></b>, evaluation report: <b><a href="models/it-lucene/it-tokenizer.txt">it-tokenizer.txt</a></b>, training algorithm: <b>MAXENT_QN</b>, evaluation score: <b>0.9968303230424088</b></li>
<li>model file: <b><a href="models/it-lucene/it-pos-tagger.onlpm">it-pos-tagger.onlpm</a></b>, evaluation report: <b><a href="models/it-lucene/it-pos-tagger.txt">it-pos-tagger.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>0.9505762914302777</b></li>
<li>model file: <b><a href="models/it-lucene/it-lemmatizer.onlpm">it-lemmatizer.onlpm</a></b>, evaluation report: <b><a href="models/it-lucene/it-lemmatizer.txt">it-lemmatizer.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>0.9842102120035832</b></li>
</ul>
</li>
</ul>
</li>
<li>language code: <b>ja</b>, language name: <b>japanese</b>, training sample size: <b>16k</b>
<ul>

<li>ja-simple
<ul>

<li>model file: <b><a href="models/ja-simple/ja-sentence-detector.onlpm">ja-sentence-detector.onlpm</a></b>, evaluation report: <b><a href="models/ja-simple/ja-sentence-detector.txt">ja-sentence-detector.txt</a></b>, training algorithm: <b>MAXENT_QN</b>, evaluation score: <b>0.01408450704225352</b></li>
<li>model file: <b><a href="models/ja-simple/ja-tokenizer.onlpm">ja-tokenizer.onlpm</a></b>, evaluation report: <b><a href="models/ja-simple/ja-tokenizer.txt">ja-tokenizer.txt</a></b>, training algorithm: <b>NAIVEBAYES</b>, evaluation score: <b>0.8082118301067929</b></li>
<li>model file: <b><a href="models/ja-simple/ja-pos-tagger.onlpm">ja-pos-tagger.onlpm</a></b>, evaluation report: <b><a href="models/ja-simple/ja-pos-tagger.txt">ja-pos-tagger.txt</a></b>, training algorithm: <b>PERCEPTRON</b>, evaluation score: <b>0.9664465904611746</b></li>
<li>model file: <b><a href="models/ja-simple/ja-lemmatizer.onlpm">ja-lemmatizer.onlpm</a></b>, evaluation report: <b><a href="models/ja-simple/ja-lemmatizer.txt">ja-lemmatizer.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>0.9768919984233346</b></li>
</ul>
</li>
<li>ja-lucene
<ul>

<li>model file: <b><a href="models/ja-lucene/ja-sentence-detector.onlpm">ja-sentence-detector.onlpm</a></b>, evaluation report: <b><a href="models/ja-lucene/ja-sentence-detector.txt">ja-sentence-detector.txt</a></b>, training algorithm: <b>MAXENT_QN</b>, evaluation score: <b>0.9679173463839043</b></li>
<li>model file: <b><a href="models/ja-lucene/ja-tokenizer.onlpm">ja-tokenizer.onlpm</a></b>, evaluation report: <b><a href="models/ja-lucene/ja-tokenizer.txt">ja-tokenizer.txt</a></b>, training algorithm: <b>NAIVEBAYES</b>, evaluation score: <b>0.7992018020665002</b></li>
<li>model file: <b><a href="models/ja-lucene/ja-pos-tagger.onlpm">ja-pos-tagger.onlpm</a></b>, evaluation report: <b><a href="models/ja-lucene/ja-pos-tagger.txt">ja-pos-tagger.txt</a></b>, training algorithm: <b>PERCEPTRON</b>, evaluation score: <b>0.9673635394191901</b></li>
<li>model file: <b><a href="models/ja-lucene/ja-lemmatizer.onlpm">ja-lemmatizer.onlpm</a></b>, evaluation report: <b><a href="models/ja-lucene/ja-lemmatizer.txt">ja-lemmatizer.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>0.9778042308359993</b></li>
</ul>
</li>
</ul>
</li>
<li>language code: <b>ko</b>, language name: <b>korean</b>, training sample size: <b>30k</b>
<ul>

<li>ko-simple
<ul>

<li>model file: <b><a href="models/ko-simple/ko-sentence-detector.onlpm">ko-sentence-detector.onlpm</a></b>, evaluation report: <b><a href="models/ko-simple/ko-sentence-detector.txt">ko-sentence-detector.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>0.9404110601803933</b></li>
<li>model file: <b><a href="models/ko-simple/ko-tokenizer.onlpm">ko-tokenizer.onlpm</a></b>, evaluation report: <b><a href="models/ko-simple/ko-tokenizer.txt">ko-tokenizer.txt</a></b>, training algorithm: <b>MAXENT_QN</b>, evaluation score: <b>0.99312093905354</b></li>
<li>model file: <b><a href="models/ko-simple/ko-pos-tagger.onlpm">ko-pos-tagger.onlpm</a></b>, evaluation report: <b><a href="models/ko-simple/ko-pos-tagger.txt">ko-pos-tagger.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>0.9027726001863933</b></li>
<li>model file: <b><a href="models/ko-simple/ko-lemmatizer.onlpm">ko-lemmatizer.onlpm</a></b>, evaluation report: <b><a href="models/ko-simple/ko-lemmatizer.txt">ko-lemmatizer.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>0.8706430568499534</b></li>
</ul>
</li>
<li>ko-lucene
<ul>

<li>model file: <b><a href="models/ko-lucene/ko-sentence-detector.onlpm">ko-sentence-detector.onlpm</a></b>, evaluation report: <b><a href="models/ko-lucene/ko-sentence-detector.txt">ko-sentence-detector.txt</a></b>, training algorithm: <b>MAXENT_QN</b>, evaluation score: <b>0.9415594022784435</b></li>
<li>model file: <b><a href="models/ko-lucene/ko-tokenizer.onlpm">ko-tokenizer.onlpm</a></b>, evaluation report: <b><a href="models/ko-lucene/ko-tokenizer.txt">ko-tokenizer.txt</a></b>, training algorithm: <b>MAXENT_QN</b>, evaluation score: <b>0.9921742547577611</b></li>
<li>model file: <b><a href="models/ko-lucene/ko-pos-tagger.onlpm">ko-pos-tagger.onlpm</a></b>, evaluation report: <b><a href="models/ko-lucene/ko-pos-tagger.txt">ko-pos-tagger.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>0.9031220876048462</b></li>
<li>model file: <b><a href="models/ko-lucene/ko-lemmatizer.onlpm">ko-lemmatizer.onlpm</a></b>, evaluation report: <b><a href="models/ko-lucene/ko-lemmatizer.txt">ko-lemmatizer.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>0.9057781919850886</b></li>
</ul>
</li>
</ul>
</li>
<li>language code: <b>no</b>, language name: <b>norwegian</b>, training sample size: <b>38k</b>
<ul>

<li>no-simple
<ul>

<li>model file: <b><a href="models/no-simple/no-sentence-detector.onlpm">no-sentence-detector.onlpm</a></b>, evaluation report: <b><a href="models/no-simple/no-sentence-detector.txt">no-sentence-detector.txt</a></b>, training algorithm: <b>MAXENT_QN</b>, evaluation score: <b>0.8659768715763848</b></li>
<li>model file: <b><a href="models/no-simple/no-tokenizer.onlpm">no-tokenizer.onlpm</a></b>, evaluation report: <b><a href="models/no-simple/no-tokenizer.txt">no-tokenizer.txt</a></b>, training algorithm: <b>MAXENT_QN</b>, evaluation score: <b>0.9990836873632157</b></li>
<li>model file: <b><a href="models/no-simple/no-pos-tagger.onlpm">no-pos-tagger.onlpm</a></b>, evaluation report: <b><a href="models/no-simple/no-pos-tagger.txt">no-pos-tagger.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>0.9484970784892476</b></li>
<li>model file: <b><a href="models/no-simple/no-lemmatizer.onlpm">no-lemmatizer.onlpm</a></b>, evaluation report: <b><a href="models/no-simple/no-lemmatizer.txt">no-lemmatizer.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>0.9661315583398591</b></li>
</ul>
</li>
<li>no-lucene
<ul>

<li>model file: <b><a href="models/no-lucene/no-sentence-detector.onlpm">no-sentence-detector.onlpm</a></b>, evaluation report: <b><a href="models/no-lucene/no-sentence-detector.txt">no-sentence-detector.txt</a></b>, training algorithm: <b>MAXENT_QN</b>, evaluation score: <b>0.8647331221057762</b></li>
<li>model file: <b><a href="models/no-lucene/no-tokenizer.onlpm">no-tokenizer.onlpm</a></b>, evaluation report: <b><a href="models/no-lucene/no-tokenizer.txt">no-tokenizer.txt</a></b>, training algorithm: <b>MAXENT_QN</b>, evaluation score: <b>0.9988986371571353</b></li>
<li>model file: <b><a href="models/no-lucene/no-pos-tagger.onlpm">no-pos-tagger.onlpm</a></b>, evaluation report: <b><a href="models/no-lucene/no-pos-tagger.txt">no-pos-tagger.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>0.9454518252543387</b></li>
<li>model file: <b><a href="models/no-lucene/no-lemmatizer.onlpm">no-lemmatizer.onlpm</a></b>, evaluation report: <b><a href="models/no-lucene/no-lemmatizer.txt">no-lemmatizer.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>0.9645721125074805</b></li>
</ul>
</li>
</ul>
</li>
<li>language code: <b>pl</b>, language name: <b>polish</b>, training sample size: <b>36k</b>
<ul>

<li>pl-simple
<ul>

<li>model file: <b><a href="models/pl-simple/pl-sentence-detector.onlpm">pl-sentence-detector.onlpm</a></b>, evaluation report: <b><a href="models/pl-simple/pl-sentence-detector.txt">pl-sentence-detector.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>0.954483442887263</b></li>
<li>model file: <b><a href="models/pl-simple/pl-tokenizer.onlpm">pl-tokenizer.onlpm</a></b>, evaluation report: <b><a href="models/pl-simple/pl-tokenizer.txt">pl-tokenizer.txt</a></b>, training algorithm: <b>MAXENT_QN</b>, evaluation score: <b>0.9982110193169711</b></li>
<li>model file: <b><a href="models/pl-simple/pl-pos-tagger.onlpm">pl-pos-tagger.onlpm</a></b>, evaluation report: <b><a href="models/pl-simple/pl-pos-tagger.txt">pl-pos-tagger.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>0.9624727691232685</b></li>
<li>model file: <b><a href="models/pl-simple/pl-lemmatizer.onlpm">pl-lemmatizer.onlpm</a></b>, evaluation report: <b><a href="models/pl-simple/pl-lemmatizer.txt">pl-lemmatizer.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>0.9651239261786345</b></li>
</ul>
</li>
<li>pl-lucene
<ul>

<li>model file: <b><a href="models/pl-lucene/pl-sentence-detector.onlpm">pl-sentence-detector.onlpm</a></b>, evaluation report: <b><a href="models/pl-lucene/pl-sentence-detector.txt">pl-sentence-detector.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>0.9547314895200297</b></li>
<li>model file: <b><a href="models/pl-lucene/pl-tokenizer.onlpm">pl-tokenizer.onlpm</a></b>, evaluation report: <b><a href="models/pl-lucene/pl-tokenizer.txt">pl-tokenizer.txt</a></b>, training algorithm: <b>MAXENT_QN</b>, evaluation score: <b>0.998073217726397</b></li>
<li>model file: <b><a href="models/pl-lucene/pl-pos-tagger.onlpm">pl-pos-tagger.onlpm</a></b>, evaluation report: <b><a href="models/pl-lucene/pl-pos-tagger.txt">pl-pos-tagger.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>0.9605864316608118</b></li>
<li>model file: <b><a href="models/pl-lucene/pl-lemmatizer.onlpm">pl-lemmatizer.onlpm</a></b>, evaluation report: <b><a href="models/pl-lucene/pl-lemmatizer.txt">pl-lemmatizer.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>0.965114626271651</b></li>
</ul>
</li>
</ul>
</li>
<li>language code: <b>pt</b>, language name: <b>portuguese</b>, training sample size: <b>51k</b>
<ul>

<li>pt-simple
<ul>

<li>model file: <b><a href="models/pt-simple/pt-sentence-detector.onlpm">pt-sentence-detector.onlpm</a></b>, evaluation report: <b><a href="models/pt-simple/pt-sentence-detector.txt">pt-sentence-detector.txt</a></b>, training algorithm: <b>MAXENT_QN</b>, evaluation score: <b>0.7505770118479768</b></li>
<li>model file: <b><a href="models/pt-simple/pt-tokenizer.onlpm">pt-tokenizer.onlpm</a></b>, evaluation report: <b><a href="models/pt-simple/pt-tokenizer.txt">pt-tokenizer.txt</a></b>, training algorithm: <b>MAXENT_QN</b>, evaluation score: <b>0.9984746219759079</b></li>
<li>model file: <b><a href="models/pt-simple/pt-pos-tagger.onlpm">pt-pos-tagger.onlpm</a></b>, evaluation report: <b><a href="models/pt-simple/pt-pos-tagger.txt">pt-pos-tagger.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>0.953143470075741</b></li>
<li>model file: <b><a href="models/pt-simple/pt-lemmatizer.onlpm">pt-lemmatizer.onlpm</a></b>, evaluation report: <b><a href="models/pt-simple/pt-lemmatizer.txt">pt-lemmatizer.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>0.961188214176262</b></li>
</ul>
</li>
<li>pt-lucene
<ul>

<li>model file: <b><a href="models/pt-lucene/pt-sentence-detector.onlpm">pt-sentence-detector.onlpm</a></b>, evaluation report: <b><a href="models/pt-lucene/pt-sentence-detector.txt">pt-sentence-detector.txt</a></b>, training algorithm: <b>MAXENT_QN</b>, evaluation score: <b>0.7429361179361178</b></li>
<li>model file: <b><a href="models/pt-lucene/pt-tokenizer.onlpm">pt-tokenizer.onlpm</a></b>, evaluation report: <b><a href="models/pt-lucene/pt-tokenizer.txt">pt-tokenizer.txt</a></b>, training algorithm: <b>MAXENT_QN</b>, evaluation score: <b>0.9983304031573484</b></li>
<li>model file: <b><a href="models/pt-lucene/pt-pos-tagger.onlpm">pt-pos-tagger.onlpm</a></b>, evaluation report: <b><a href="models/pt-lucene/pt-pos-tagger.txt">pt-pos-tagger.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>0.9491111280040833</b></li>
<li>model file: <b><a href="models/pt-lucene/pt-lemmatizer.onlpm">pt-lemmatizer.onlpm</a></b>, evaluation report: <b><a href="models/pt-lucene/pt-lemmatizer.txt">pt-lemmatizer.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>0.9613066472638815</b></li>
</ul>
</li>
</ul>
</li>
<li>language code: <b>ru</b>, language name: <b>russian</b>, training sample size: <b>99k</b>
<ul>

<li>ru-simple
<ul>

<li>model file: <b><a href="models/ru-simple/ru-sentence-detector.onlpm">ru-sentence-detector.onlpm</a></b>, evaluation report: <b><a href="models/ru-simple/ru-sentence-detector.txt">ru-sentence-detector.txt</a></b>, training algorithm: <b>MAXENT_QN</b>, evaluation score: <b>0.9254442205532148</b></li>
<li>model file: <b><a href="models/ru-simple/ru-tokenizer.onlpm">ru-tokenizer.onlpm</a></b>, evaluation report: <b><a href="models/ru-simple/ru-tokenizer.txt">ru-tokenizer.txt</a></b>, training algorithm: <b>MAXENT_QN</b>, evaluation score: <b>0.9955184125208999</b></li>
<li>model file: <b><a href="models/ru-simple/ru-pos-tagger.onlpm">ru-pos-tagger.onlpm</a></b>, evaluation report: <b><a href="models/ru-simple/ru-pos-tagger.txt">ru-pos-tagger.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>0.9626311164503176</b></li>
<li>model file: <b><a href="models/ru-simple/ru-lemmatizer.onlpm">ru-lemmatizer.onlpm</a></b>, evaluation report: <b><a href="models/ru-simple/ru-lemmatizer.txt">ru-lemmatizer.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>0.9758845841536802</b></li>
</ul>
</li>
<li>ru-lucene
<ul>

<li>model file: <b><a href="models/ru-lucene/ru-sentence-detector.onlpm">ru-sentence-detector.onlpm</a></b>, evaluation report: <b><a href="models/ru-lucene/ru-sentence-detector.txt">ru-sentence-detector.txt</a></b>, training algorithm: <b>MAXENT_QN</b>, evaluation score: <b>0.9391851818057393</b></li>
<li>model file: <b><a href="models/ru-lucene/ru-tokenizer.onlpm">ru-tokenizer.onlpm</a></b>, evaluation report: <b><a href="models/ru-lucene/ru-tokenizer.txt">ru-tokenizer.txt</a></b>, training algorithm: <b>MAXENT_QN</b>, evaluation score: <b>0.9961138795110674</b></li>
<li>model file: <b><a href="models/ru-lucene/ru-pos-tagger.onlpm">ru-pos-tagger.onlpm</a></b>, evaluation report: <b><a href="models/ru-lucene/ru-pos-tagger.txt">ru-pos-tagger.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>0.9617084675690237</b></li>
<li>model file: <b><a href="models/ru-lucene/ru-lemmatizer.onlpm">ru-lemmatizer.onlpm</a></b>, evaluation report: <b><a href="models/ru-lucene/ru-lemmatizer.txt">ru-lemmatizer.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>0.9763378671094154</b></li>
</ul>
</li>
</ul>
</li>
<li>language code: <b>sv</b>, language name: <b>swedish</b>, training sample size: <b>10k</b>
<ul>

<li>sv-simple
<ul>

<li>model file: <b><a href="models/sv-simple/sv-sentence-detector.onlpm">sv-sentence-detector.onlpm</a></b>, evaluation report: <b><a href="models/sv-simple/sv-sentence-detector.txt">sv-sentence-detector.txt</a></b>, training algorithm: <b>MAXENT_QN</b>, evaluation score: <b>0.8524173027989821</b></li>
<li>model file: <b><a href="models/sv-simple/sv-tokenizer.onlpm">sv-tokenizer.onlpm</a></b>, evaluation report: <b><a href="models/sv-simple/sv-tokenizer.txt">sv-tokenizer.txt</a></b>, training algorithm: <b>MAXENT_QN</b>, evaluation score: <b>0.9990025435140392</b></li>
<li>model file: <b><a href="models/sv-simple/sv-pos-tagger.onlpm">sv-pos-tagger.onlpm</a></b>, evaluation report: <b><a href="models/sv-simple/sv-pos-tagger.txt">sv-pos-tagger.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>0.9429397974961344</b></li>
<li>model file: <b><a href="models/sv-simple/sv-lemmatizer.onlpm">sv-lemmatizer.onlpm</a></b>, evaluation report: <b><a href="models/sv-simple/sv-lemmatizer.txt">sv-lemmatizer.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>0.9575539927178413</b></li>
</ul>
</li>
<li>sv-lucene
<ul>

<li>model file: <b><a href="models/sv-lucene/sv-sentence-detector.onlpm">sv-sentence-detector.onlpm</a></b>, evaluation report: <b><a href="models/sv-lucene/sv-sentence-detector.txt">sv-sentence-detector.txt</a></b>, training algorithm: <b>MAXENT_QN</b>, evaluation score: <b>0.8518046709129512</b></li>
<li>model file: <b><a href="models/sv-lucene/sv-tokenizer.onlpm">sv-tokenizer.onlpm</a></b>, evaluation report: <b><a href="models/sv-lucene/sv-tokenizer.txt">sv-tokenizer.txt</a></b>, training algorithm: <b>MAXENT_QN</b>, evaluation score: <b>0.9990025932575304</b></li>
<li>model file: <b><a href="models/sv-lucene/sv-pos-tagger.onlpm">sv-pos-tagger.onlpm</a></b>, evaluation report: <b><a href="models/sv-lucene/sv-pos-tagger.txt">sv-pos-tagger.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>0.9370043393685471</b></li>
<li>model file: <b><a href="models/sv-lucene/sv-lemmatizer.onlpm">sv-lemmatizer.onlpm</a></b>, evaluation report: <b><a href="models/sv-lucene/sv-lemmatizer.txt">sv-lemmatizer.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>0.9555090029427902</b></li>
</ul>
</li>
</ul>
</li>
<li>language code: <b>uk</b>, language name: <b>ukrainian</b>, training sample size: <b>6k</b>
<ul>

<li>uk-simple
<ul>

<li>model file: <b><a href="models/uk-simple/uk-sentence-detector.onlpm">uk-sentence-detector.onlpm</a></b>, evaluation report: <b><a href="models/uk-simple/uk-sentence-detector.txt">uk-sentence-detector.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>0.8921071687183201</b></li>
<li>model file: <b><a href="models/uk-simple/uk-tokenizer.onlpm">uk-tokenizer.onlpm</a></b>, evaluation report: <b><a href="models/uk-simple/uk-tokenizer.txt">uk-tokenizer.txt</a></b>, training algorithm: <b>PERCEPTRON</b>, evaluation score: <b>0.996005326231691</b></li>
<li>model file: <b><a href="models/uk-simple/uk-pos-tagger.onlpm">uk-pos-tagger.onlpm</a></b>, evaluation report: <b><a href="models/uk-simple/uk-pos-tagger.txt">uk-pos-tagger.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>0.945929987347111</b></li>
<li>model file: <b><a href="models/uk-simple/uk-lemmatizer.onlpm">uk-lemmatizer.onlpm</a></b>, evaluation report: <b><a href="models/uk-simple/uk-lemmatizer.txt">uk-lemmatizer.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>0.9483762125685364</b></li>
</ul>
</li>
<li>uk-lucene
<ul>

<li>model file: <b><a href="models/uk-lucene/uk-sentence-detector.onlpm">uk-sentence-detector.onlpm</a></b>, evaluation report: <b><a href="models/uk-lucene/uk-sentence-detector.txt">uk-sentence-detector.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>0.8937093275488069</b></li>
<li>model file: <b><a href="models/uk-lucene/uk-tokenizer.onlpm">uk-tokenizer.onlpm</a></b>, evaluation report: <b><a href="models/uk-lucene/uk-tokenizer.txt">uk-tokenizer.txt</a></b>, training algorithm: <b>MAXENT_QN</b>, evaluation score: <b>0.9958807850739035</b></li>
<li>model file: <b><a href="models/uk-lucene/uk-pos-tagger.onlpm">uk-pos-tagger.onlpm</a></b>, evaluation report: <b><a href="models/uk-lucene/uk-pos-tagger.txt">uk-pos-tagger.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>0.9448334036271615</b></li>
<li>model file: <b><a href="models/uk-lucene/uk-lemmatizer.onlpm">uk-lemmatizer.onlpm</a></b>, evaluation report: <b><a href="models/uk-lucene/uk-lemmatizer.txt">uk-lemmatizer.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>0.9494727962884859</b></li>
</ul>
</li>
</ul>
</li>
<li>language code: <b>zh</b>, language name: <b>chinese</b>, training sample size: <b>9k</b>
<ul>

<li>zh-simple
<ul>

<li>model file: <b><a href="models/zh-simple/zh-sentence-detector.onlpm">zh-sentence-detector.onlpm</a></b>, evaluation report: <b><a href="models/zh-simple/zh-sentence-detector.txt">zh-sentence-detector.txt</a></b>, training algorithm: <b>PERCEPTRON</b>, evaluation score: <b>0.01</b></li>
<li>model file: <b><a href="models/zh-simple/zh-tokenizer.onlpm">zh-tokenizer.onlpm</a></b>, evaluation report: <b><a href="models/zh-simple/zh-tokenizer.txt">zh-tokenizer.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>0.900867645283149</b></li>
<li>model file: <b><a href="models/zh-simple/zh-pos-tagger.onlpm">zh-pos-tagger.onlpm</a></b>, evaluation report: <b><a href="models/zh-simple/zh-pos-tagger.txt">zh-pos-tagger.txt</a></b>, training algorithm: <b>PERCEPTRON</b>, evaluation score: <b>0.9439259574797662</b></li>
<li>model file: <b><a href="models/zh-simple/zh-lemmatizer.onlpm">zh-lemmatizer.onlpm</a></b>, evaluation report: <b><a href="models/zh-simple/zh-lemmatizer.txt">zh-lemmatizer.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>0.9996901986601092</b></li>
</ul>
</li>
<li>zh-lucene
<ul>

<li>model file: <b><a href="models/zh-lucene/zh-sentence-detector.onlpm">zh-sentence-detector.onlpm</a></b>, evaluation report: <b><a href="models/zh-lucene/zh-sentence-detector.txt">zh-sentence-detector.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>0.9798224374495561</b></li>
<li>model file: <b><a href="models/zh-lucene/zh-tokenizer.onlpm">zh-tokenizer.onlpm</a></b>, evaluation report: <b><a href="models/zh-lucene/zh-tokenizer.txt">zh-tokenizer.txt</a></b>, training algorithm: <b>MAXENT_QN</b>, evaluation score: <b>0.9196061063929557</b></li>
<li>model file: <b><a href="models/zh-lucene/zh-pos-tagger.onlpm">zh-pos-tagger.onlpm</a></b>, evaluation report: <b><a href="models/zh-lucene/zh-pos-tagger.txt">zh-pos-tagger.txt</a></b>, training algorithm: <b>PERCEPTRON</b>, evaluation score: <b>0.9408972228815571</b></li>
<li>model file: <b><a href="models/zh-lucene/zh-lemmatizer.onlpm">zh-lemmatizer.onlpm</a></b>, evaluation report: <b><a href="models/zh-lucene/zh-lemmatizer.txt">zh-lemmatizer.txt</a></b>, training algorithm: <b>MAXENT</b>, evaluation score: <b>0.9998021995411029</b></li>
</ul>
</li>
</ul>
</li>
</ol>
        </main>
      </div>
    </div>
    <hr/>
    <footer>
      <div class="container-fluid">
        <div class="row-fluid">
            <p>&#169;      2022
</p>
        </div>
      </div>
    </footer>
<script>
	if(anchors) {
	  anchors.add();
	}
</script>
  </body>
</html>